# ğŸ•¸ï¸ WebWeave â€“ Smart Web Info Extractor

WebWeave is a powerful, terminal-based and web-integrated application that intelligently crawls, scrapes, and extracts structured information from any target website. From company details and contact info to legal pages, portfolios, and upcoming events â€“ WebWeave organizes it all, and stores the results in **MongoDB** with a unique SHA-256 hash key for retrieval.

---

## ğŸš€ Features

- ğŸ” **Deep Website Crawling** via Selenium and BeautifulSoup
- ğŸ§  **Smart Extraction** of structured categories:
  - Company Overview
  - Services, Categories & Subcategories
  - Contact Info (Email, Phone)
  - News, Events, Team, Legal, Portfolio
- ğŸ§± **Data Storage** in MongoDB with unique SHA-256 keys
- ğŸ“¦ **Dual Output Formats**: JSON and TXT
- ğŸ§  **Modular Design** for integration with web apps
- ğŸ“œ **Terminal Interface** (CLI-based usage)
- ğŸ”‘ **SHA-256 Key Generation** using (email + URL) for unique access
- ğŸ“¤ **Web App Compatibility**: Can be deployed in a backend server setup

---

## ğŸ› ï¸ Technologies Used

- **Language**: Python  
- **Libraries**: `selenium`, `beautifulsoup4`, `re`, `pymongo`, `hashlib`, `json`, `os`  
- **Database**: MongoDB Atlas (Cloud or Local)  
- **CLI Input**: `python main.py <email> <link>`

---

## ğŸ§ª How It Works

1. Receives `email` and `link` via command-line or web app
2. Initializes a headless **Selenium** session and crawls all internal links
3. Extracts text, metadata, and identifies category-specific content using regex
4. Saves the structured data to:
   - `output_data/all_data.json`
   - `output_data/all_data.txt`
5. Uploads to **MongoDB** using a hash key derived from `email + link`
6. Returns a success message with the hash key as retrieval ID

---

## ğŸ“‚ Folder Structure

```
webweave/
â”œâ”€â”€ output_data/            # Stores all_data.json and all_data.txt
â”œâ”€â”€ main.py                 # Main crawling & extraction script
â”œâ”€â”€ utils/                  # SHA, normalization, link extractor
â”œâ”€â”€ templates/              # (Optional) Web frontend
â”œâ”€â”€ case_study.pdf          # ğŸ“˜ Visual documentation & process report
â”œâ”€â”€ README.md
```

---

## ğŸ§ª Running the Script

```bash
python main.py your_email@example.com https://example.com
```

> ğŸ“ This will start crawling, extract all structured data, and store it in MongoDB with a generated hash key.

---

## ğŸ“„ Output Example

```
output_data/
â”œâ”€â”€ all_data.json    # Structured data dump
â””â”€â”€ all_data.txt     # Readable format for manual inspection
```

MongoDB Entry:
```json
{
  "key": "9b3ef5c1a3a8d472...f49e01",
  "text_data": "All extracted information as a string"
}
```

---

## ğŸ§© Use Case Integration

WebWeave was designed as a module for a larger **Lead Generation + Intelligence Platform** where users submit a URL, and get clean structured insights about the business or product ecosystem of that site.

It can also be integrated into:
- Web Audit Tools
- B2B Data Enrichment Platforms
- SaaS Company Profiling Apps

---

## ğŸ“˜ Case Study

ğŸ“ **`webweave_webscrapping.pdf`** â€” Included in the root directory.

The case study covers:
- Problem Statement & Objective
- System Architecture & Flowchart
- Sample Screenshots
- Technologies Used
- Challenges Faced
- Key Learnings & Future Scope

---

## ğŸ’¡ Example Use Case

> "Given a startup's website, retrieve their mission, services, team members, news updates, contact channels, and upload all into a knowledge database."

---

## ğŸ¤ Contributing

Feel free to fork this repo and submit improvements like:
- Multilingual scraping
- ML-based text classification
- Frontend Dashboard
- PDF/CSV Export Options

---

## ğŸ“œ License

MIT License Â© 2025 Botnist Devs

---
> ğŸ•¸ï¸ *Weave through the web. Extract the essence.*
